environment: "Production"

image:
  # Repository to pull the image from
  repository: "ghcr.io/sneaksanddata/arcane-operator"
  
  # Tag to pull (defaults to the chart appVersion)
  tag: ""
  
  # Image pull policy
  pullPolicy: "IfNotPresent"

# Image pull secrets for private repositories
imagePullSecrets: []

# Override the application name
nameOverride: ""

# Fullname override
fullnameOverride: ""

# Service account configuration
serviceAccount:
  
  # Specifies whether a service account should be created
  create: true
  
  # Annotations to add to the service account
  annotations: {}
  
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# CRD configuration
customResourceDefinitions:
  
  # Set to true to create CRDs for this operator
  # Otherwise, the operator will expect the CRDs to be pre-installed
  create: true
  
### Role Based Access Control configuration
rbac:
  
  # Specifies whether RBAC resources should be created
  clusterRole:
    
    # Allows the Arcane Operator to create and manage jobs in the cluster
    jobEditor:
      additionalLabels: {}
      additionalAnnotations: {}
      create: true
      nameOverride: ""
      
    # Allows the Arcane Operator to read jobs in the cluster
    jobViewer:
      additionalLabels: {}
      additionalAnnotations: {}
      create: true
      nameOverride: ""
      
    # Allows managing the StreamingJobTemplate custom resources
    jobTemplateEditor:
      additionalLabels: {}
      additionalAnnotations: {}
      create: true
      nameOverride: ""
    
    # Allows the Arcane Operator to read the StreamingJobTemplate custom resources
    jobTemplateViewer:
      additionalLabels: {}
      additionalAnnotations: {}
      create: true
      nameOverride: ""
      
    # Allows managing the StreamClass custom resources
    streamClassEditor:
      additionalLabels: {}
      additionalAnnotations: {}
      create: true
      nameOverride: ""

    # Allows the Arcane Operator to read the StreamClass custom resources
    streamClassViewer:
      additionalLabels: {}
      additionalAnnotations: {}
      create: true
      nameOverride: ""

    # Allows managing the StreamClass custom resources
    backfillRequestEditor:
      additionalLabels: {}
      additionalAnnotations: {}
      create: true
      nameOverride: ""

    # Allows managing the StreamClass custom resources
    backfillRequestViewer:
      additionalLabels: {}
      additionalAnnotations: {}
      create: true
      nameOverride: ""

  # This parameter determines whether role binding resources need to be created.
  # If you have any roles in your configuration set to 'true', then this parameter for creating role binding resources
  # should also be set to 'true'.
  clusterRoleBindings:
    additionalLabels: {}
    additionalAnnotations: {}
    create: true
    
# Additional labels for the deployment and pods
additionalLabels: {}
# Example:
#
#  app.my-company.com/name: arcane-operator
#  app.my-company.com/component: streaming

# Additional labels for the deployment and pods
additionalAnnotations: {}
# Example:
#
#  app.my-company.com/name: arcane-operator
#  app.my-company.com/component: streaming
#  app.my-company.com/application: arcane

# Extra environment variables to set in the deployment
extraEnv: {}
# Example:
#
#  - name: ASPNETCORE_ENVIRONMENT
#    value: production

# Extra environment variables referencing a ConfigMap or Secret
extraEnvFrom: {}
# Example:
#
#  envFrom:
#    - configMapRef:
#        name: custom-api-access-token

# Extra volumes to add to the deployment
extraVolumes: {}
# Example:
# 
#  - name: data-volume
#    emptyDir:
#      sizeLimit: 500Mi

# Extra volumes to add to the deployment
extraVolumeMounts: {}
# Example:
#
#  - mountPath: /data
#    name: data-volume

# Resources constraints. By default, the operator does not specify any constraints to allow for easier deployment
resources: {}
# Example:
#
#  requests:
#    cpu: 1
#    memory: 1Gi
#  limits:
#    cpu: 1
#    memory: 1Gi

# Node labels for pod assignment
tolerations: { }

# Node labels for pod assignment
affinity: { }

# Security context settings for the container
securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000
  seccompProfile:
    type: RuntimeDefault

settings:

  # Configuration for the health probes
  probes:

    ## Address override for the probes to listen on (overrides the port setting or interface binding)
    ## If not set, defaults to "0.0.0.0:<port>"
    listenAddrOverride: ""

    ## Port for the health probes to listen on
    port: 8888

    ## Timeout for write operations
    ## If not set, defaults to 15s
    writeTimeout: ""

    ## Timeout for read operations
    ## If not set, defaults to 15s
    readTimeout: ""

    ## Timeout for server shutdown
    ## If not set, defaults to 5s
    shutdownTimeout: ""

  # Generic telemetry settings
  telemetry:
    # Log level for the operator
    logLevel: "Info"

    # Name of the cluster the operator is deployed in
    clusterName: "arcane-cluster"

    # Metrics bind port
    metricsPort: 9090

    # Address to bind the metrics endpoint to
    # Note that if this is overridden, a corresponding Service resource must be created to expose the metrics endpoint
    metricsBindAddressOverride: ""


# Observability settings for Datadog
datadog:

  # if enabled, will set Datadog-specific environment variables on the container
  enabled: false

  # Datadog endpoint to sink logs to
  endpoint: "datadoghq.eu"

  # Name for a Secret resource that contains Datadog API Key to use for log submissions
  apiKeySecret: "secretName"

  # Key in the secret that contains datadog api key
  apiKeySecretKey: "secretKey"

  # Datadog Service Name parameter
  serviceName: "arcane-operator"

  # value to use as a DogStatsd server url
  # Examples: udp://127.0.0.1:8125 or unix:///path/to/dsd.socket
  # https://github.com/DataDog/datadog-go?tab=readme-ov-file#unix-domain-sockets-client
  statsdUrl: unix:///var/run/datadog/dsd.socket

  # enables metric origin detection by setting DD_ENTITY_ID
  enableOriginDetection: true

  # Datadog tracing via Orchestrion
  tracer:
    # enable tracer
    enabled: false

    # UDS/HTTP url for the tracer
    agent_url: unix:///var/run/datadog/apm.socket

    # disable Datadog product info collection
    disable_vendor_telemetry: true

    # service environment tag
    service_env: development